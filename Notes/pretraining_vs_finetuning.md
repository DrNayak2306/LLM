# Pretraining vs Finetuning

Creating an LLM = pretraining + finetuning

## Pretraining
Training on a large and diverse unlabelled dataset.

## Finetuning
Training on a small specific labelled dataset catered to applications.

GPT is a pretrained / foundational model (non specific.)"